{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd1293dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableSequence\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d0740ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gpt_4o_mini = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3debb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello! I'm an AI language model created by OpenAI. I'm here to assist you with a wide range of questions and topics. How can I help you today?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 13, 'total_tokens': 46, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C5MS031IWkhmSV8ergl8PgyDNC3z4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--0a5d10a4-389f-4cb4-833f-6422bf3014bb-0' usage_metadata={'input_tokens': 13, 'output_tokens': 33, 'total_tokens': 46, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = model_gpt_4o_mini.invoke(\"Hi, who are you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91205505",
   "metadata": {},
   "source": [
    "### Exercise 1 - completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24585b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:  The wind is\n",
      "response: content=\"The wind is the movement of air caused by differences in atmospheric pressure. It plays a crucial role in weather patterns, climate, and the distribution of heat and moisture around the Earth. Wind can vary in speed and direction, and it can have significant effects on the environment, including erosion, pollination, and the dispersal of seeds. Additionally, wind is harnessed for energy through wind turbines, contributing to renewable energy sources. If you have a specific aspect of wind you'd like to explore further, feel free to ask!\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 10, 'total_tokens': 114, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-C5MV5AhLeA8cMtdylUBRSMlLPggTE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--d89bc9ff-7ac9-49b4-902b-fda542e3070a-0' usage_metadata={'input_tokens': 10, 'output_tokens': 104, 'total_tokens': 114, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "prompt = \" The wind is\"\n",
    "\n",
    "response = model_gpt_4o_mini.invoke(prompt)\n",
    "print(f\"prompt: {prompt}\")\n",
    "print(f\"response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c1fa50",
   "metadata": {},
   "source": [
    "### Zero shot prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57f0af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: Classify the following statement as true or false: \n",
      "            'The Eiffel Tower is located in Berlin.'\n",
      "\n",
      "            Answer:\n",
      "\n",
      "\n",
      "response : False. The Eiffel Tower is located in Paris, France, not Berlin.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Classify the following statement as true or false: \n",
    "            'The Eiffel Tower is located in Berlin.'\n",
    "\n",
    "            Answer:\n",
    "\"\"\"\n",
    "response = model_gpt_4o_mini.invoke(prompt)\n",
    "print(f\"prompt: {prompt}\\n\")\n",
    "print(f\"response : {response.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65317519",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9780bf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: \n",
      "Classify the following movie review as either 'positive' or 'negative'.\n",
      "\n",
      "Review: \"I was extremely disappointed by this film. The plot was predictable, the acting was wooden, and the special effects looked cheap. I can't recommend this to anyone.\"\n",
      "\n",
      "Classification:\n",
      "\n",
      "\n",
      "response : Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Prompt for Movie Review Classification\n",
    "movie_review_prompt = \"\"\"\n",
    "Classify the following movie review as either 'positive' or 'negative'.\n",
    "\n",
    "Review: \"I was extremely disappointed by this film. The plot was predictable, the acting was wooden, and the special effects looked cheap. I can't recommend this to anyone.\"\n",
    "\n",
    "Classification:\n",
    "\"\"\"\n",
    "response = model_gpt_4o_mini.invoke(movie_review_prompt)\n",
    "print(f\"prompt: {movie_review_prompt}\\n\")\n",
    "print(f\"response : {response.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25e1a54",
   "metadata": {},
   "source": [
    "## One-shot prompting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee5051da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: Here is an example of translating a sentence from English to Spanish:\n",
      "\n",
      "            English: “How is the weather today?”\n",
      "            French: “Como esta el clima hoy?”\n",
      "\n",
      "            Now, translate the following sentence from English to Spanish:\n",
      "\n",
      "            English: “Where is the nearest supermarket?”\n",
      "\n",
      "response: Spanish: “¿Dónde está el supermercado más cercano?”\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Here is an example of translating a sentence from English to Spanish:\n",
    "\n",
    "            English: “How is the weather today?”\n",
    "            French: “Como esta el clima hoy?”\n",
    "            \n",
    "            Now, translate the following sentence from English to Spanish:\n",
    "            \n",
    "            English: “Where is the nearest supermarket?”\n",
    "\"\"\"\n",
    "response = model_gpt_4o_mini.invoke(prompt)\n",
    "print(f\"prompt: {prompt}\")\n",
    "print(f\"response: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f8a7cf",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eebddb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: \n",
      "Here is an example of extracting keywords from a sentence:\n",
      "\n",
      "Sentence: \"Cloud computing offers businesses flexibility, scalability, and cost-efficiency for their IT infrastructure needs.\"\n",
      "Keywords: cloud computing, flexibility, scalability, cost-efficiency, IT infrastructure\n",
      "\n",
      "---\n",
      "\n",
      "Now, please extract the main keywords from the following sentence:\n",
      "\n",
      "Sentence: \"Sustainable agriculture practices focus on biodiversity, soil health, water conservation, and reducing chemical inputs.\"\n",
      "Keywords:\n",
      "\n",
      "response: Keywords: sustainable agriculture, biodiversity, soil health, water conservation, chemical inputs\n"
     ]
    }
   ],
   "source": [
    "# 3. One-shot prompt for keyword extraction\n",
    "keyword_extraction_prompt = \"\"\"\n",
    "Here is an example of extracting keywords from a sentence:\n",
    "\n",
    "Sentence: \"Cloud computing offers businesses flexibility, scalability, and cost-efficiency for their IT infrastructure needs.\"\n",
    "Keywords: cloud computing, flexibility, scalability, cost-efficiency, IT infrastructure\n",
    "\n",
    "---\n",
    "\n",
    "Now, please extract the main keywords from the following sentence:\n",
    "\n",
    "Sentence: \"Sustainable agriculture practices focus on biodiversity, soil health, water conservation, and reducing chemical inputs.\"\n",
    "Keywords:\n",
    "\"\"\"\n",
    "\n",
    "response = model_gpt_4o_mini.invoke(keyword_extraction_prompt)\n",
    "print(f\"prompt: {keyword_extraction_prompt}\")\n",
    "print(f\"response: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eff8ac",
   "metadata": {},
   "source": [
    "## Few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e866693b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: Here are few examples of classifying emotions in statements:\n",
      "\n",
      "            Statement: 'I just won my first marathon!'\n",
      "            Emotion: Joy\n",
      "\n",
      "            Statement: 'I can't believe I lost my keys again.'\n",
      "            Emotion: Frustration\n",
      "\n",
      "            Statement: 'My best friend is moving to another country.'\n",
      "            Emotion: Sadness\n",
      "\n",
      "            Now, classify the emotion in the following statement:\n",
      "            Statement: 'That movie was so scary I had to cover my eyes.’\n",
      "\n",
      "\n",
      "\n",
      "response: Emotion: Fear\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Here are few examples of classifying emotions in statements:\n",
    "\n",
    "            Statement: 'I just won my first marathon!'\n",
    "            Emotion: Joy\n",
    "            \n",
    "            Statement: 'I can't believe I lost my keys again.'\n",
    "            Emotion: Frustration\n",
    "            \n",
    "            Statement: 'My best friend is moving to another country.'\n",
    "            Emotion: Sadness\n",
    "            \n",
    "            Now, classify the emotion in the following statement:\n",
    "            Statement: 'That movie was so scary I had to cover my eyes.\n",
    "            \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = model_gpt_4o_mini.invoke(prompt)\n",
    "print(f\"prompt: {prompt}\")\n",
    "print(f\"response: {response.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51effd32",
   "metadata": {},
   "source": [
    "## Chain-of-thoght (CoT) Promopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90276f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: Consider the problem: 'A store had 22 apples. They sold 15 apples today and got a new delivery of 8 apples. \n",
      "            How many apples are there now?'\n",
      "\n",
      "            Break down each step of your calculation\n",
      "\n",
      "\n",
      "response: To solve the problem, we can break it down into clear steps:\n",
      "\n",
      "1. **Initial Number of Apples**: The store starts with 22 apples.\n",
      "\n",
      "2. **Apples Sold**: The store sold 15 apples today. To find the number of apples remaining after the sale, we subtract the number of apples sold from the initial number:\n",
      "   \\[\n",
      "   22 \\text{ apples} - 15 \\text{ apples} = 7 \\text{ apples}\n",
      "   \\]\n",
      "\n",
      "3. **New Delivery of Apples**: The store received a new delivery of 8 apples. To find the total number of apples after the delivery, we add the number of new apples to the remaining apples:\n",
      "   \\[\n",
      "   7 \\text{ apples} + 8 \\text{ apples} = 15 \\text{ apples}\n",
      "   \\]\n",
      "\n",
      "4. **Final Count of Apples**: After selling 15 apples and receiving a delivery of 8 apples, the total number of apples in the store now is 15.\n",
      "\n",
      "Thus, the final answer is:\n",
      "\\[\n",
      "\\text{The store now has 15 apples.}\n",
      "\\]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Consider the problem: 'A store had 22 apples. They sold 15 apples today and got a new delivery of 8 apples. \n",
    "            How many apples are there now?'\n",
    "\n",
    "            Break down each step of your calculation\n",
    "\n",
    "\"\"\"\n",
    "response = model_gpt_4o_mini.invoke(prompt)\n",
    "print(f\"prompt: {prompt}\")\n",
    "print(f\"response: {response.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b1a05b",
   "metadata": {},
   "source": [
    "## exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ade57033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: \n",
      "Explain how to make a peanut butter and jelly sandwich.\n",
      "\n",
      "Break down each step of the process in detail, from gathering ingredients to finishing the sandwich.\n",
      "\n",
      "response: Making a peanut butter and jelly sandwich is a simple yet satisfying process. Here’s a detailed breakdown of each step, from gathering ingredients to finishing the sandwich.\n",
      "\n",
      "### Step 1: Gather Ingredients and Tools\n",
      "\n",
      "**Ingredients:**\n",
      "1. Bread (2 slices) - You can use white, whole wheat, or any type of bread you prefer.\n",
      "2. Peanut butter - Creamy or crunchy, depending on your preference.\n",
      "3. Jelly or jam - Choose your favorite flavor (e.g., grape, strawberry, raspberry).\n",
      "\n",
      "**Tools:**\n",
      "1. A butter knife or a spoon - For spreading the peanut butter and jelly.\n",
      "2. A plate - To assemble your sandwich.\n",
      "3. A clean surface - To work on, such as a countertop or table.\n",
      "\n",
      "### Step 2: Prepare Your Workspace\n",
      "\n",
      "1. **Clean the Surface:** Ensure your workspace is clean to avoid contamination.\n",
      "2. **Lay Out the Plate:** Place the plate on the clean surface where you will assemble the sandwich.\n",
      "\n",
      "### Step 3: Take Out the Bread\n",
      "\n",
      "1. **Open the Bread Package:** Carefully open the bag of bread.\n",
      "2. **Select Two Slices:** Take out two slices of bread and lay them flat on the plate, side by side.\n",
      "\n",
      "### Step 4: Spread the Peanut Butter\n",
      "\n",
      "1. **Open the Peanut Butter Jar:** Remove the lid from the peanut butter jar.\n",
      "2. **Scoop the Peanut Butter:** Use the butter knife or spoon to scoop out a generous amount of peanut butter (about 2 tablespoons is a good starting point).\n",
      "3. **Spread the Peanut Butter:** \n",
      "   - Place the peanut butter on one slice of bread.\n",
      "   - Use the knife to spread it evenly across the surface, reaching the edges for full coverage. You can spread it as thick or thin as you like.\n",
      "\n",
      "### Step 5: Spread the Jelly or Jam\n",
      "\n",
      "1. **Open the Jelly or Jam Jar:** Remove the lid from the jelly or jam jar.\n",
      "2. **Scoop the Jelly:** Use a clean spoon or the other side of the knife to scoop out a similar amount of jelly (about 1-2 tablespoons).\n",
      "3. **Spread the Jelly:**\n",
      "   - Place the jelly on the second slice of bread.\n",
      "   - Use the knife to spread it evenly across the surface, again reaching the edges.\n",
      "\n",
      "### Step 6: Assemble the Sandwich\n",
      "\n",
      "1. **Combine the Slices:** Carefully place the slice of bread with peanut butter on top of the slice with jelly, aligning the edges.\n",
      "2. **Press Gently:** Press down lightly to help the two slices stick together.\n",
      "\n",
      "### Step 7: Cut the Sandwich (Optional)\n",
      "\n",
      "1. **Decide on Cutting:** If you prefer, you can cut the sandwich in half or into quarters. \n",
      "2. **Use the Knife:** Use a clean knife to cut through the sandwich. You can cut diagonally for triangles or straight down the middle for rectangles.\n",
      "\n",
      "### Step 8: Serve and Enjoy\n",
      "\n",
      "1. **Place on a Clean Surface:** If you cut the sandwich, you can place the halves back on the plate.\n",
      "2. **Add Extras (Optional):** You can serve the sandwich with a side of fruit, chips, or a glass of milk if desired.\n",
      "3. **Enjoy Your Sandwich:** Take a bite and savor the delicious combination of peanut butter and jelly!\n",
      "\n",
      "### Step 9: Clean Up\n",
      "\n",
      "1. **Put Away Ingredients:** Seal the peanut butter and jelly jars and put them back in the pantry or refrigerator.\n",
      "2. **Dispose of Any Waste:** Throw away any packaging or scraps.\n",
      "3. **Wash Utensils:** Clean the knife and any other tools you used with soap and water.\n",
      "\n",
      "And there you have it! A delicious peanut butter and jelly sandwich made step by step. Enjoy!\n"
     ]
    }
   ],
   "source": [
    "# 2. Prompt for explaining a process\n",
    "sandwich_making_prompt = \"\"\"\n",
    "Explain how to make a peanut butter and jelly sandwich.\n",
    "\n",
    "Break down each step of the process in detail, from gathering ingredients to finishing the sandwich.\n",
    "\"\"\"\n",
    "response = model_gpt_4o_mini.invoke(sandwich_making_prompt)\n",
    "print(f\"prompt: {sandwich_making_prompt}\")\n",
    "print(f\"response: {response.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dc566b",
   "metadata": {},
   "source": [
    "## Self-consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e427a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: When I was 6, my sister was half of my age. Now I am 70, what age is my sister?\n",
      "\n",
      "            Provide two independent calculations and explanations, then determine the most consistent result.\n",
      "\n",
      "\n",
      "response: Let's break down the problem step by step.\n",
      "\n",
      "### Calculation 1:\n",
      "1. When you were 6 years old, your sister was half your age, which means she was 3 years old (6 / 2 = 3).\n",
      "2. The age difference between you and your sister is 6 - 3 = 3 years.\n",
      "3. Now that you are 70 years old, we can find your sister's age by subtracting the age difference from your current age:\n",
      "   - Your sister's age = 70 - 3 = 67 years old.\n",
      "\n",
      "### Calculation 2:\n",
      "1. You are currently 70 years old.\n",
      "2. Since you were 6 years old and your sister was 3 years old, the age difference is 3 years.\n",
      "3. To find your sister's current age, we can also add the age difference to her age when you were 6:\n",
      "   - Your sister's age when you were 6 = 3 years.\n",
      "   - The time that has passed since you were 6 is 70 - 6 = 64 years.\n",
      "   - Therefore, your sister's current age = 3 + 64 = 67 years old.\n",
      "\n",
      "### Conclusion:\n",
      "Both calculations consistently show that your sister is 67 years old now. Thus, the most consistent result is that your sister is **67 years old**.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"When I was 6, my sister was half of my age. Now I am 70, what age is my sister?\n",
    "\n",
    "            Provide two independent calculations and explanations, then determine the most consistent result.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = model_gpt_4o_mini.invoke(prompt)\n",
    "print(f\"prompt: {prompt}\")\n",
    "print(f\"response: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c546c",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60dd2e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['adjective', 'topic'], input_types={}, partial_variables={}, template='Tell me a {adjective} joke about {topic}.')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Tell me a {adjective} joke about {topic}.\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90458857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about AI.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(adjective=\"funny\", topic=\"AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97464336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Define a function to ensure proper formatting\n",
    "def format_prompt(variables):\n",
    "    return prompt_template.format(**variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1fca6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the AI go broke?\n",
      "\n",
      "Because it kept losing its cache!\n"
     ]
    }
   ],
   "source": [
    "joke_chain = (RunnableLambda(format_prompt) | model_gpt_4o_mini | StrOutputParser())\n",
    "\n",
    "response = joke_chain.invoke({\"adjective\": \"funny\", \"topic\": \"AI\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74f5b90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the fish blush?\n",
      "\n",
      "Because it saw the ocean's bottom and realized it was all just a little too shallow.\n"
     ]
    }
   ],
   "source": [
    "response = joke_chain.invoke({\"adjective\": \"sad\", \"topic\": \"fish\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75be1a3",
   "metadata": {},
   "source": [
    "# Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0b6b296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 21st century's rapid technological advancements, including AI, machine learning, and the Internet of Things, are transforming industries like healthcare, education, and transportation, enhancing productivity and creating a more interconnected society.\n"
     ]
    }
   ],
   "source": [
    "content = \"\"\"\n",
    "    The rapid advancement of technology in the 21st century has transformed various industries, including healthcare, education, and transportation. \n",
    "    Innovations such as artificial intelligence, machine learning, and the Internet of Things have revolutionized how we approach everyday tasks and complex problems. \n",
    "    For instance, AI-powered diagnostic tools are improving the accuracy and speed of medical diagnoses, while smart transportation systems are making cities more efficient and reducing traffic congestion. \n",
    "    Moreover, online learning platforms are making education more accessible to people around the world, breaking down geographical and financial barriers. \n",
    "    These technological developments are not only enhancing productivity but also contributing to a more interconnected and informed society.\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"Summarize the {content} in one sentence.\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the LCEL chain\n",
    "summarize_chain = (\n",
    "    RunnableLambda(format_prompt)\n",
    "    | model_gpt_4o_mini \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "summary = summarize_chain.invoke({\"content\": content})\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7427ef22",
   "metadata": {},
   "source": [
    "## Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66dfda07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rocky and solid planets in the solar system are Mercury, Venus, Earth, and Mars.\n"
     ]
    }
   ],
   "source": [
    "content = \"\"\"\n",
    "    The solar system consists of the Sun, eight planets, their moons, dwarf planets, and smaller objects like asteroids and comets. \n",
    "    The inner planets—Mercury, Venus, Earth, and Mars—are rocky and solid. \n",
    "    The outer planets—Jupiter, Saturn, Uranus, and Neptune—are much larger and gaseous.\n",
    "\"\"\"\n",
    "\n",
    "question = \"Which planets in the solar system are rocky and solid?\"\n",
    "\n",
    "template = \"\"\"\n",
    "    Answer the {question} based on the {content}.\n",
    "    Respond \"Unsure about answer\" if not sure about the answer.\n",
    "    \n",
    "    Answer:\n",
    "    \n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the LCEL chain\n",
    "qa_chain = (\n",
    "    RunnableLambda(format_prompt)\n",
    "    | model_gpt_4o_mini \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "response = qa_chain.invoke({\"question\": question, \"content\": content})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b7092d",
   "metadata": {},
   "source": [
    "## Text Clasification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2294a97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Music\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "    The concert last night was an exhilarating experience with outstanding performances by all artists.\n",
    "\"\"\"\n",
    "\n",
    "categories = \"Entertainment, Food and Dining, Technology, Literature, Music.\"\n",
    "\n",
    "template = \"\"\"\n",
    "    Classify the {text} into one of the {categories}.\n",
    "    \n",
    "    Category:\n",
    "    \n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the LCEL chain\n",
    "classification_chain = (\n",
    "    RunnableLambda(format_prompt)\n",
    "    | model_gpt_4o_mini\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "response = classification_chain.invoke({\"text\": text, \"categories\": categories})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7264d1d3",
   "metadata": {},
   "source": [
    "## Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aab8a048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To retrieve the names and email addresses of all customers from the 'customers' table who have made a purchase in the last 30 days, you can use the following SQL query. This query assumes that there is a relationship between the 'customers' table and the 'purchases' table, typically through a customer ID.\n",
      "\n",
      "Here is the SQL query:\n",
      "\n",
      "```sql\n",
      "SELECT c.name, c.email\n",
      "FROM customers c\n",
      "JOIN purchases p ON c.customer_id = p.customer_id\n",
      "WHERE p.purchase_date >= NOW() - INTERVAL 30 DAY;\n",
      "```\n",
      "\n",
      "In this query:\n",
      "- We select the `name` and `email` columns from the `customers` table (aliased as `c`).\n",
      "- We join the `customers` table with the `purchases` table (aliased as `p`) on the `customer_id` column, which is assumed to be the common key between the two tables.\n",
      "- We filter the results to include only those purchases made in the last 30 days using the `WHERE` clause with a condition on the `purchase_date` column. \n",
      "\n",
      "Make sure to adjust the column names and table structure according to your actual database schema if they differ.\n"
     ]
    }
   ],
   "source": [
    "description = \"\"\"\n",
    "    Retrieve the names and email addresses of all customers from the 'customers' table who have made a purchase in the last 30 days. \n",
    "    The table 'purchases' contains a column 'purchase_date'\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "    Generate an SQL query based on the {description}\n",
    "    \n",
    "    SQL Query:\n",
    "    \n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the LCEL chain\n",
    "sql_generation_chain = (\n",
    "    RunnableLambda(format_prompt) \n",
    "    | model_gpt_4o_mini \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "sql_query = sql_generation_chain.invoke({\"description\": description})\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba47709",
   "metadata": {},
   "source": [
    "## Role playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c068d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  As your basketball trainer, my role is to help you develop your skills, improve your game, and build your confidence on the court. I’m here to provide personalized coaching, whether that’s working on your shooting technique, ball handling, defensive strategies, or overall fitness. I’ll also support you mentally, helping you stay motivated and focused on your goals. Remember, every player has their own unique journey, and I’m excited to be a part of yours! Let’s work together to unlock your full potential and have fun while doing it! What specific areas are you looking to improve?\n",
      "Answer:  Absolutely! I'm excited to help you jump higher! Improving your vertical leap is a combination of strength, technique, and practice. Here are some friendly tips to get you started:\n",
      "\n",
      "1. **Strength Training**: Focus on building strength in your legs and core. Exercises like squats, lunges, and deadlifts are fantastic for developing the muscles you need for jumping. Don’t forget to include calf raises to strengthen your calves!\n",
      "\n",
      "2. **Plyometrics**: Incorporate plyometric exercises into your routine. Box jumps, jump squats, and depth jumps are great for developing explosive power. Start with lower heights and gradually increase as you get more comfortable.\n",
      "\n",
      "3. **Jump Technique**: Work on your jumping technique. A proper jump involves bending your knees, swinging your arms, and using your core for stability. Practice jumping with good form, focusing on a quick and explosive upward motion.\n",
      "\n",
      "4. **Flexibility**: Don’t underestimate the power of flexibility! Stretching your muscles, especially your hamstrings, quads, and calves, can help improve your range of motion and overall jumping ability. Consider incorporating yoga or dynamic stretching into your routine.\n",
      "\n",
      "5. **Consistency**: Like any skill, improving your jump takes time and dedication. Set aside time each week to focus on your jumping exercises, and track your progress. Celebrate your improvements, no matter how small!\n",
      "\n",
      "6. **Nutrition and Recovery**: Fuel your body with nutritious foods to support your training. Make sure you’re getting enough protein, vitamins, and minerals. Also, prioritize rest and recovery—your muscles need time to rebuild and strengthen.\n",
      "\n",
      "7. **Stay Positive**: Remember, improvement takes time, so be patient with yourself. Stay positive and keep pushing your limits. Surround yourself with supportive teammates or friends who can encourage you along the way!\n",
      "\n",
      "If you stay committed and keep a positive mindset, you’ll see progress in no time. Let’s get to work on those jumps! You've got this! 🏀💪\n",
      "Answer: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "role = \"\"\"\n",
    "    basketball trainer\n",
    "\"\"\"\n",
    "\n",
    "tone = \"friendly and encouraging\"\n",
    "\n",
    "template = \"\"\"\n",
    "    You are an expert {role}. I have this question {question}. I would like our conversation to be {tone}.\n",
    "    \n",
    "    Answer:\n",
    "    \n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the LCEL chain\n",
    "roleplay_chain = (\n",
    "    RunnableLambda(format_prompt)\n",
    "    | model_gpt_4o_mini \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Create an interactive chat loop\n",
    "while True:\n",
    "    query = input(\"Question: \")\n",
    "    \n",
    "    if query.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
    "        print(\"Answer: Goodbye!\")\n",
    "        break\n",
    "        \n",
    "    response = roleplay_chain.invoke({\"role\": role, \"question\": query, \"tone\": tone})\n",
    "    print(\"Answer: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2058f1",
   "metadata": {},
   "source": [
    "## Analyze Product review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff4b50b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Analysis 1:\n",
      "- Sentiment: Positive  \n",
      "- Key Features Mentioned: Camera quality, battery life, heating during gaming  \n",
      "- Summary: The reviewer is highly satisfied with the smartphone's camera and battery performance, although they note a minor issue with heating during gaming.\n",
      "Review Analysis 2:\n",
      "- Sentiment: Negative\n",
      "- Key Features Mentioned: Speed, reliability (crashes), keyboard functionality, customer service\n",
      "- Summary: The reviewer expresses dissatisfaction with the laptop due to its poor performance, malfunctioning keyboard, and inadequate customer service.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Analyze the following product review:\n",
    "\"{review}\"\n",
    "\n",
    "Provide your analysis in the following format:\n",
    "- Sentiment: (positive, negative, or neutral)\n",
    "- Key Features Mentioned: (list the product features mentioned)\n",
    "- Summary: (one-sentence summary)\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "def format_review_prompt_template(variables):\n",
    "    return prompt_template.format(**variables)\n",
    "\n",
    "\n",
    "review_analysis_chain = (\n",
    "    RunnableLambda(format_review_prompt_template)\n",
    "    | model_gpt_4o_mini\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "reviews = [\n",
    "    \"I love this smartphone! The camera quality is exceptional and the battery lasts all day. The only downside is that it heats up a bit during gaming.\",\n",
    "    \"This laptop is terrible. It's slow, crashes frequently, and the keyboard stopped working after just two months. Customer service was unhelpful.\"\n",
    "]\n",
    "\n",
    "for i, review in enumerate(reviews):\n",
    "    analysis = review_analysis_chain.invoke({\"review\": review})\n",
    "    print(f\"Review Analysis {i + 1}:\")\n",
    "    print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872b31b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
